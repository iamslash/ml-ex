{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMgCEPEEWckTtABO7KJYEQr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iamslash/ml-ex/blob/main/pytorch/transformer/Transformer_from_the_scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BoTLB4rH1wtg",
        "outputId": "beb85a47-811f-4f19-9c1b-b0140caba4ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EncoderDecoder(\n",
            "  (encoder): Encoder(\n",
            "    (layers): ModuleList(\n",
            "      (0-1): 2 x EncoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linears): ModuleList(\n",
            "            (0-3): 4 x Linear(in_features=512, out_features=512, bias=True)\n",
            "          )\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (sublayer): ModuleList(\n",
            "          (0-1): 2 x SublayerConnection(\n",
            "            (norm): LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (norm): LayerNorm()\n",
            "  )\n",
            "  (decoder): Decoder(\n",
            "    (layers): ModuleList(\n",
            "      (0-1): 2 x DecoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linears): ModuleList(\n",
            "            (0-3): 4 x Linear(in_features=512, out_features=512, bias=True)\n",
            "          )\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (src_attn): MultiHeadedAttention(\n",
            "          (linears): ModuleList(\n",
            "            (0-3): 4 x Linear(in_features=512, out_features=512, bias=True)\n",
            "          )\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (sublayer): ModuleList(\n",
            "          (0-2): 3 x SublayerConnection(\n",
            "            (norm): LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (norm): LayerNorm()\n",
            "  )\n",
            "  (src_embed): Sequential(\n",
            "    (0): Embeddings(\n",
            "      (lut): Embedding(11, 512)\n",
            "    )\n",
            "    (1): PositionalEncoding(\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "  )\n",
            "  (tgt_embed): Sequential(\n",
            "    (0): Embeddings(\n",
            "      (lut): Embedding(11, 512)\n",
            "    )\n",
            "    (1): PositionalEncoding(\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "  )\n",
            "  (generator): Generator(\n",
            "    (proj): Linear(in_features=512, out_features=11, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Greedy Decoding 결과: tensor([[ 1,  2, 10,  3,  3,  3,  9, 10,  2,  2]])\n"
          ]
        }
      ],
      "source": [
        "# Google Colab에서 실행하기 위해 matplotlib inline 모드를 활성화합니다.\n",
        "%matplotlib inline\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math, copy\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "###############################\n",
        "# 1. 전체 모델 구조: Encoder-Decoder 아키텍처\n",
        "###############################\n",
        "\n",
        "class EncoderDecoder(nn.Module):\n",
        "    \"\"\"\n",
        "    표준 Encoder-Decoder 아키텍처.\n",
        "    encoder, decoder, src와 tgt 임베딩, 그리고 최종 출력(softmax)을 위한 generator를 포함합니다.\n",
        "    \"\"\"\n",
        "    def __init__(self, encoder, decoder, src_embed, tgt_embed, generator):\n",
        "        super(EncoderDecoder, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.src_embed = src_embed\n",
        "        self.tgt_embed = tgt_embed\n",
        "        self.generator = generator\n",
        "\n",
        "    def forward(self, src, tgt, src_mask, tgt_mask):\n",
        "        return self.decode(self.encode(src, src_mask), src_mask, tgt, tgt_mask)\n",
        "\n",
        "    def encode(self, src, src_mask):\n",
        "        return self.encoder(self.src_embed(src), src_mask)\n",
        "\n",
        "    def decode(self, memory, src_mask, tgt, tgt_mask):\n",
        "        return self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask)\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    \"출력 임베딩을 선형 변환한 후 softmax를 적용하는 모듈입니다.\"\n",
        "    def __init__(self, d_model, vocab):\n",
        "        super(Generator, self).__init__()\n",
        "        self.proj = nn.Linear(d_model, vocab)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return F.log_softmax(self.proj(x), dim=-1)\n",
        "\n",
        "###############################\n",
        "# 2. 인코더 관련 구성 요소\n",
        "###############################\n",
        "\n",
        "def clones(module, N):\n",
        "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])\n",
        "\n",
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, features, eps=1e-6):\n",
        "        super(LayerNorm, self).__init__()\n",
        "        self.a_2 = nn.Parameter(torch.ones(features))\n",
        "        self.b_2 = nn.Parameter(torch.zeros(features))\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(-1, keepdim=True)\n",
        "        std  = x.std(-1, keepdim=True)\n",
        "        return self.a_2 * (x - mean) / (std + self.eps) + self.b_2\n",
        "\n",
        "class SublayerConnection(nn.Module):\n",
        "    def __init__(self, size, dropout):\n",
        "        super(SublayerConnection, self).__init__()\n",
        "        self.norm = LayerNorm(size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, sublayer):\n",
        "        return x + self.dropout(sublayer(self.norm(x)))\n",
        "\n",
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, size, self_attn, feed_forward, dropout):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        self.self_attn = self_attn\n",
        "        self.feed_forward = feed_forward\n",
        "        self.sublayer = clones(SublayerConnection(size, dropout), 2)\n",
        "        self.size = size\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))\n",
        "        return self.sublayer[1](x, self.feed_forward)\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, layer, N):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.layers = clones(layer, N)\n",
        "        self.norm = LayerNorm(layer.size)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, mask)\n",
        "        return self.norm(x)\n",
        "\n",
        "###############################\n",
        "# 3. 디코더 관련 구성 요소\n",
        "###############################\n",
        "\n",
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, size, self_attn, src_attn, feed_forward, dropout):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "        self.size = size\n",
        "        self.self_attn = self_attn\n",
        "        self.src_attn = src_attn\n",
        "        self.feed_forward = feed_forward\n",
        "        self.sublayer = clones(SublayerConnection(size, dropout), 3)\n",
        "\n",
        "    def forward(self, x, memory, src_mask, tgt_mask):\n",
        "        m = memory\n",
        "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, tgt_mask))\n",
        "        x = self.sublayer[1](x, lambda x: self.src_attn(x, m, m, src_mask))\n",
        "        return self.sublayer[2](x, self.feed_forward)\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, layer, N):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.layers = clones(layer, N)\n",
        "        self.norm = LayerNorm(layer.size)\n",
        "\n",
        "    def forward(self, x, memory, src_mask, tgt_mask):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, memory, src_mask, tgt_mask)\n",
        "        return self.norm(x)\n",
        "\n",
        "def subsequent_mask(size):\n",
        "    attn_shape = (1, size, size)\n",
        "    subsequent_mask = np.triu(np.ones(attn_shape), k=1).astype('uint8')\n",
        "    return torch.from_numpy(subsequent_mask) == 0\n",
        "\n",
        "###############################\n",
        "# 4. Attention 메커니즘\n",
        "###############################\n",
        "\n",
        "def attention(query, key, value, mask=None, dropout=None):\n",
        "    d_k = query.size(-1)\n",
        "    scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(d_k)\n",
        "\n",
        "    if mask is not None:\n",
        "        scores = scores.masked_fill(mask == 0, -1e9)\n",
        "\n",
        "    p_attn = F.softmax(scores, dim=-1)\n",
        "\n",
        "    if dropout is not None:\n",
        "        p_attn = dropout(p_attn)\n",
        "\n",
        "    return torch.matmul(p_attn, value), p_attn\n",
        "\n",
        "class MultiHeadedAttention(nn.Module):\n",
        "    def __init__(self, h, d_model, dropout=0.1):\n",
        "        super(MultiHeadedAttention, self).__init__()\n",
        "        assert d_model % h == 0\n",
        "        self.d_k = d_model // h\n",
        "        self.h = h\n",
        "        self.linears = clones(nn.Linear(d_model, d_model), 4)\n",
        "        self.attn = None\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "    def forward(self, query, key, value, mask=None):\n",
        "        if mask is not None:\n",
        "            mask = mask.unsqueeze(1)\n",
        "        nbatches = query.size(0)\n",
        "\n",
        "        query, key, value = [\n",
        "            l(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)\n",
        "            for l, x in zip(self.linears, (query, key, value))\n",
        "        ]\n",
        "\n",
        "        x, self.attn = attention(query, key, value, mask=mask, dropout=self.dropout)\n",
        "\n",
        "        x = x.transpose(1, 2).contiguous().view(nbatches, -1, self.h * self.d_k)\n",
        "        return self.linears[-1](x)\n",
        "\n",
        "###############################\n",
        "# 5. Position-wise Feed-Forward Network\n",
        "###############################\n",
        "\n",
        "class PositionwiseFeedForward(nn.Module):\n",
        "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
        "        super(PositionwiseFeedForward, self).__init__()\n",
        "        self.w_1 = nn.Linear(d_model, d_ff)\n",
        "        self.w_2 = nn.Linear(d_ff, d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.w_2(self.dropout(F.relu(self.w_1(x))))\n",
        "\n",
        "###############################\n",
        "# 6. 임베딩과 Positional Encoding\n",
        "###############################\n",
        "\n",
        "class Embeddings(nn.Module):\n",
        "    def __init__(self, d_model, vocab):\n",
        "        super(Embeddings, self).__init__()\n",
        "        self.lut = nn.Embedding(vocab, d_model)\n",
        "        self.d_model = d_model\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.lut(x) * math.sqrt(self.d_model)\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, dropout, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:, :x.size(1)]\n",
        "        return self.dropout(x)\n",
        "\n",
        "###############################\n",
        "# 7. 전체 모델 구성: make_model\n",
        "###############################\n",
        "\n",
        "def make_model(src_vocab, tgt_vocab, N=6, d_model=512, d_ff=2048, h=8, dropout=0.1):\n",
        "    c = copy.deepcopy\n",
        "    attn = MultiHeadedAttention(h, d_model, dropout)\n",
        "    ff = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
        "    position = PositionalEncoding(d_model, dropout)\n",
        "\n",
        "    model = EncoderDecoder(\n",
        "        Encoder(EncoderLayer(d_model, c(attn), c(ff), dropout), N),\n",
        "        Decoder(DecoderLayer(d_model, c(attn), c(attn), c(ff), dropout), N),\n",
        "        nn.Sequential(Embeddings(d_model, src_vocab), c(position)),\n",
        "        nn.Sequential(Embeddings(d_model, tgt_vocab), c(position)),\n",
        "        Generator(d_model, tgt_vocab)\n",
        "    )\n",
        "\n",
        "    for p in model.parameters():\n",
        "        if p.dim() > 1:\n",
        "            nn.init.xavier_uniform_(p)\n",
        "    return model\n",
        "\n",
        "###############################\n",
        "# 8. 학습 관련 구성 요소\n",
        "###############################\n",
        "\n",
        "class Batch:\n",
        "    def __init__(self, src, trg=None, pad=0):\n",
        "        self.src = src\n",
        "        self.src_mask = (src != pad).unsqueeze(-2)\n",
        "        if trg is not None:\n",
        "            self.trg = trg[:, :-1]\n",
        "            self.trg_y = trg[:, 1:]\n",
        "            self.trg_mask = self.make_std_mask(self.trg, pad)\n",
        "            self.ntokens = (self.trg_y != pad).data.sum()\n",
        "\n",
        "    @staticmethod\n",
        "    def make_std_mask(tgt, pad):\n",
        "        tgt_mask = (tgt != pad).unsqueeze(-2)\n",
        "        tgt_mask = tgt_mask & subsequent_mask(tgt.size(-1)).type_as(tgt_mask.data)\n",
        "        return tgt_mask\n",
        "\n",
        "class LabelSmoothing(nn.Module):\n",
        "    def __init__(self, size, padding_idx, smoothing=0.0):\n",
        "        super(LabelSmoothing, self).__init__()\n",
        "        self.criterion = nn.KLDivLoss(reduction='sum')\n",
        "        self.padding_idx = padding_idx\n",
        "        self.confidence = 1.0 - smoothing\n",
        "        self.smoothing = smoothing\n",
        "        self.size = size\n",
        "        self.true_dist = None\n",
        "\n",
        "    def forward(self, x, target):\n",
        "        assert x.size(1) == self.size\n",
        "        true_dist = x.data.clone()\n",
        "        true_dist.fill_(self.smoothing / (self.size - 2))\n",
        "        true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
        "        true_dist[:, self.padding_idx] = 0\n",
        "        mask = torch.nonzero(target.data == self.padding_idx)\n",
        "        if mask.dim() > 0:\n",
        "            true_dist.index_fill_(0, mask.squeeze(), 0.0)\n",
        "        self.true_dist = true_dist\n",
        "        return self.criterion(x, true_dist)\n",
        "\n",
        "class NoamOpt:\n",
        "    def __init__(self, model_size, factor, warmup, optimizer):\n",
        "        self.optimizer = optimizer\n",
        "        self._step = 0\n",
        "        self.warmup = warmup\n",
        "        self.factor = factor\n",
        "        self.model_size = model_size\n",
        "        self._rate = 0\n",
        "\n",
        "    def step(self):\n",
        "        self._step += 1\n",
        "        rate = self.rate()\n",
        "        for p in self.optimizer.param_groups:\n",
        "            p['lr'] = rate\n",
        "        self._rate = rate\n",
        "        self.optimizer.step()\n",
        "\n",
        "    def rate(self, step=None):\n",
        "        if step is None:\n",
        "            step = self._step\n",
        "        return self.factor * (self.model_size ** (-0.5) *\n",
        "                              min(step ** (-0.5), step * self.warmup ** (-1.5)))\n",
        "\n",
        "def get_std_opt(model):\n",
        "    return NoamOpt(model.src_embed[0].d_model, 2, 4000,\n",
        "                   torch.optim.Adam(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9))\n",
        "\n",
        "###############################\n",
        "# 9. Greedy Decoding (추론)\n",
        "###############################\n",
        "\n",
        "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
        "    memory = model.encode(src, src_mask)\n",
        "    ys = torch.ones(1, 1).fill_(start_symbol).type_as(src.data)\n",
        "\n",
        "    for i in range(max_len - 1):\n",
        "        out = model.decode(memory, src_mask, ys,\n",
        "                           subsequent_mask(ys.size(1)).type_as(src.data))\n",
        "        prob = model.generator(out[:, -1])\n",
        "        _, next_word = torch.max(prob, dim=1)\n",
        "        next_word = next_word.item()\n",
        "        ys = torch.cat([ys, torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=1)\n",
        "    return ys\n",
        "\n",
        "###############################\n",
        "# 10. 예시: 모델 생성 및 Greedy Decoding 테스트\n",
        "###############################\n",
        "\n",
        "# 어휘 크기를 11로 설정하여 토큰 인덱스 0~10 사용 가능\n",
        "tmp_model = make_model(11, 11, N=2)\n",
        "print(tmp_model)\n",
        "\n",
        "plt.figure(figsize=(5,5))\n",
        "plt.imshow(subsequent_mask(20)[0])\n",
        "plt.title(\"Subsequent Mask\")\n",
        "plt.show()\n",
        "\n",
        "# 예시 입력 (토큰 1~10 사용)\n",
        "src = torch.LongTensor([[1,2,3,4,5,6,7,8,9,10]])\n",
        "src_mask = (src != 0).unsqueeze(-2)\n",
        "result = greedy_decode(tmp_model, src, src_mask, max_len=10, start_symbol=1)\n",
        "print(\"Greedy Decoding 결과:\", result)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Google Colab에서 실행하기 위해 matplotlib inline 모드를 활성화합니다.\n",
        "%matplotlib inline\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math, copy\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "###############################################\n",
        "# 1. 전체 모델 구조: Encoder-Decoder 아키텍처\n",
        "###############################################\n",
        "\n",
        "class EncoderDecoder(nn.Module):\n",
        "    \"\"\"\n",
        "    표준 Encoder-Decoder 아키텍처.\n",
        "    encoder, decoder, src와 tgt 임베딩, 그리고 최종 출력(softmax)을 위한 generator를 포함합니다.\n",
        "    \"\"\"\n",
        "    def __init__(self, encoder, decoder, src_embed, tgt_embed, generator):\n",
        "        super(EncoderDecoder, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.src_embed = src_embed\n",
        "        self.tgt_embed = tgt_embed\n",
        "        self.generator = generator\n",
        "\n",
        "    def forward(self, src, tgt, src_mask, tgt_mask):\n",
        "        return self.decode(self.encode(src, src_mask), src_mask, tgt, tgt_mask)\n",
        "\n",
        "    def encode(self, src, src_mask):\n",
        "        return self.encoder(self.src_embed(src), src_mask)\n",
        "\n",
        "    def decode(self, memory, src_mask, tgt, tgt_mask):\n",
        "        return self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask)\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    \"출력 임베딩을 선형 변환한 후 softmax를 적용하는 모듈입니다.\"\n",
        "    def __init__(self, d_model, vocab):\n",
        "        super(Generator, self).__init__()\n",
        "        self.proj = nn.Linear(d_model, vocab)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return F.log_softmax(self.proj(x), dim=-1)\n",
        "\n",
        "###############################################\n",
        "# 2. 인코더 관련 구성 요소\n",
        "###############################################\n",
        "\n",
        "def clones(module, N):\n",
        "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])\n",
        "\n",
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, features, eps=1e-6):\n",
        "        super(LayerNorm, self).__init__()\n",
        "        self.a_2 = nn.Parameter(torch.ones(features))\n",
        "        self.b_2 = nn.Parameter(torch.zeros(features))\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(-1, keepdim=True)\n",
        "        std  = x.std(-1, keepdim=True)\n",
        "        return self.a_2 * (x - mean) / (std + self.eps) + self.b_2\n",
        "\n",
        "class SublayerConnection(nn.Module):\n",
        "    def __init__(self, size, dropout):\n",
        "        super(SublayerConnection, self).__init__()\n",
        "        self.norm = LayerNorm(size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, sublayer):\n",
        "        return x + self.dropout(sublayer(self.norm(x)))\n",
        "\n",
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, size, self_attn, feed_forward, dropout):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        self.self_attn = self_attn\n",
        "        self.feed_forward = feed_forward\n",
        "        self.sublayer = clones(SublayerConnection(size, dropout), 2)\n",
        "        self.size = size\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))\n",
        "        return self.sublayer[1](x, self.feed_forward)\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, layer, N):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.layers = clones(layer, N)\n",
        "        self.norm = LayerNorm(layer.size)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, mask)\n",
        "        return self.norm(x)\n",
        "\n",
        "###############################################\n",
        "# 3. 디코더 관련 구성 요소\n",
        "###############################################\n",
        "\n",
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, size, self_attn, src_attn, feed_forward, dropout):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "        self.size = size\n",
        "        self.self_attn = self_attn\n",
        "        self.src_attn = src_attn\n",
        "        self.feed_forward = feed_forward\n",
        "        self.sublayer = clones(SublayerConnection(size, dropout), 3)\n",
        "\n",
        "    def forward(self, x, memory, src_mask, tgt_mask):\n",
        "        m = memory\n",
        "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, tgt_mask))\n",
        "        x = self.sublayer[1](x, lambda x: self.src_attn(x, m, m, src_mask))\n",
        "        return self.sublayer[2](x, self.feed_forward)\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, layer, N):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.layers = clones(layer, N)\n",
        "        self.norm = LayerNorm(layer.size)\n",
        "\n",
        "    def forward(self, x, memory, src_mask, tgt_mask):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, memory, src_mask, tgt_mask)\n",
        "        return self.norm(x)\n",
        "\n",
        "def subsequent_mask(size):\n",
        "    \"미래 단어들을 마스킹합니다. (upper-triangular matrix)\"\n",
        "    attn_shape = (1, size, size)\n",
        "    subsequent_mask = np.triu(np.ones(attn_shape), k=1).astype('uint8')\n",
        "    return torch.from_numpy(subsequent_mask) == 0\n",
        "\n",
        "###############################################\n",
        "# 4. Attention 메커니즘\n",
        "###############################################\n",
        "\n",
        "def attention(query, key, value, mask=None, dropout=None):\n",
        "    d_k = query.size(-1)\n",
        "    scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(d_k)\n",
        "\n",
        "    if mask is not None:\n",
        "        scores = scores.masked_fill(mask == 0, -1e9)\n",
        "\n",
        "    p_attn = F.softmax(scores, dim=-1)\n",
        "\n",
        "    if dropout is not None:\n",
        "        p_attn = dropout(p_attn)\n",
        "\n",
        "    return torch.matmul(p_attn, value), p_attn\n",
        "\n",
        "class MultiHeadedAttention(nn.Module):\n",
        "    def __init__(self, h, d_model, dropout=0.1):\n",
        "        super(MultiHeadedAttention, self).__init__()\n",
        "        assert d_model % h == 0\n",
        "        self.d_k = d_model // h\n",
        "        self.h = h\n",
        "        self.linears = clones(nn.Linear(d_model, d_model), 4)\n",
        "        self.attn = None\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "    def forward(self, query, key, value, mask=None):\n",
        "        if mask is not None:\n",
        "            mask = mask.unsqueeze(1)\n",
        "        nbatches = query.size(0)\n",
        "\n",
        "        query, key, value = [\n",
        "            l(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)\n",
        "            for l, x in zip(self.linears, (query, key, value))\n",
        "        ]\n",
        "\n",
        "        x, self.attn = attention(query, key, value, mask=mask, dropout=self.dropout)\n",
        "\n",
        "        x = x.transpose(1, 2).contiguous().view(nbatches, -1, self.h * self.d_k)\n",
        "        return self.linears[-1](x)\n",
        "\n",
        "###############################################\n",
        "# 5. Position-wise Feed-Forward Network\n",
        "###############################################\n",
        "\n",
        "class PositionwiseFeedForward(nn.Module):\n",
        "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
        "        super(PositionwiseFeedForward, self).__init__()\n",
        "        self.w_1 = nn.Linear(d_model, d_ff)\n",
        "        self.w_2 = nn.Linear(d_ff, d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.w_2(self.dropout(F.relu(self.w_1(x))))\n",
        "\n",
        "###############################################\n",
        "# 6. 임베딩과 Positional Encoding\n",
        "###############################################\n",
        "\n",
        "class Embeddings(nn.Module):\n",
        "    def __init__(self, d_model, vocab):\n",
        "        super(Embeddings, self).__init__()\n",
        "        self.lut = nn.Embedding(vocab, d_model)\n",
        "        self.d_model = d_model\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.lut(x) * math.sqrt(self.d_model)\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, dropout, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:, :x.size(1)]\n",
        "        return self.dropout(x)\n",
        "\n",
        "###############################################\n",
        "# 7. 전체 모델 구성: make_model\n",
        "###############################################\n",
        "\n",
        "def make_model(src_vocab, tgt_vocab, N=6, d_model=512, d_ff=2048, h=8, dropout=0.1):\n",
        "    c = copy.deepcopy\n",
        "    attn = MultiHeadedAttention(h, d_model, dropout)\n",
        "    ff = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
        "    position = PositionalEncoding(d_model, dropout)\n",
        "\n",
        "    model = EncoderDecoder(\n",
        "        Encoder(EncoderLayer(d_model, c(attn), c(ff), dropout), N),\n",
        "        Decoder(DecoderLayer(d_model, c(attn), c(attn), c(ff), dropout), N),\n",
        "        nn.Sequential(Embeddings(d_model, src_vocab), c(position)),\n",
        "        nn.Sequential(Embeddings(d_model, tgt_vocab), c(position)),\n",
        "        Generator(d_model, tgt_vocab)\n",
        "    )\n",
        "\n",
        "    for p in model.parameters():\n",
        "        if p.dim() > 1:\n",
        "            nn.init.xavier_uniform_(p)\n",
        "    return model\n",
        "\n",
        "###############################################\n",
        "# 8. 학습 관련 구성 요소 (Batch, Label Smoothing, NoamOpt)\n",
        "###############################################\n",
        "\n",
        "class Batch:\n",
        "    def __init__(self, src, trg=None, pad=0):\n",
        "        self.src = src\n",
        "        self.src_mask = (src != pad).unsqueeze(-2)\n",
        "        if trg is not None:\n",
        "            self.trg = trg[:, :-1]\n",
        "            self.trg_y = trg[:, 1:]\n",
        "            self.trg_mask = self.make_std_mask(self.trg, pad)\n",
        "            self.ntokens = (self.trg_y != pad).data.sum()\n",
        "\n",
        "    @staticmethod\n",
        "    def make_std_mask(tgt, pad):\n",
        "        tgt_mask = (tgt != pad).unsqueeze(-2)\n",
        "        tgt_mask = tgt_mask & subsequent_mask(tgt.size(-1)).type_as(tgt_mask.data)\n",
        "        return tgt_mask\n",
        "\n",
        "class LabelSmoothing(nn.Module):\n",
        "    def __init__(self, size, padding_idx, smoothing=0.0):\n",
        "        super(LabelSmoothing, self).__init__()\n",
        "        self.criterion = nn.KLDivLoss(reduction='sum')\n",
        "        self.padding_idx = padding_idx\n",
        "        self.confidence = 1.0 - smoothing\n",
        "        self.smoothing = smoothing\n",
        "        self.size = size\n",
        "        self.true_dist = None\n",
        "\n",
        "    def forward(self, x, target):\n",
        "        assert x.size(1) == self.size\n",
        "        true_dist = x.data.clone()\n",
        "        true_dist.fill_(self.smoothing / (self.size - 2))\n",
        "        true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
        "        true_dist[:, self.padding_idx] = 0\n",
        "        mask = torch.nonzero(target.data == self.padding_idx)\n",
        "        if mask.dim() > 0:\n",
        "            true_dist.index_fill_(0, mask.squeeze(), 0.0)\n",
        "        self.true_dist = true_dist\n",
        "        return self.criterion(x, true_dist)\n",
        "\n",
        "class NoamOpt:\n",
        "    def __init__(self, model_size, factor, warmup, optimizer):\n",
        "        self.optimizer = optimizer\n",
        "        self._step = 0\n",
        "        self.warmup = warmup\n",
        "        self.factor = factor\n",
        "        self.model_size = model_size\n",
        "        self._rate = 0\n",
        "\n",
        "    def step(self):\n",
        "        self._step += 1\n",
        "        rate = self.rate()\n",
        "        for p in self.optimizer.param_groups:\n",
        "            p['lr'] = rate\n",
        "        self._rate = rate\n",
        "        self.optimizer.step()\n",
        "\n",
        "    def rate(self, step=None):\n",
        "        if step is None:\n",
        "            step = self._step\n",
        "        return self.factor * (self.model_size ** (-0.5) *\n",
        "                              min(step ** (-0.5), step * self.warmup ** (-1.5)))\n",
        "\n",
        "def get_std_opt(model):\n",
        "    return NoamOpt(model.src_embed[0].d_model, 2, 4000,\n",
        "                   torch.optim.Adam(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9))\n",
        "\n",
        "###############################################\n",
        "# 9. Greedy Decoding (추론)\n",
        "###############################################\n",
        "\n",
        "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
        "    \"Greedy 방식으로 문장을 생성합니다.\"\n",
        "    memory = model.encode(src, src_mask)\n",
        "    ys = torch.ones(1, 1).fill_(start_symbol).type_as(src.data)\n",
        "\n",
        "    for i in range(max_len - 1):\n",
        "        out = model.decode(memory, src_mask, ys,\n",
        "                           subsequent_mask(ys.size(1)).type_as(src.data))\n",
        "        prob = model.generator(out[:, -1])\n",
        "        _, next_word = torch.max(prob, dim=1)\n",
        "        next_word = next_word.item()\n",
        "        ys = torch.cat([ys, torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=1)\n",
        "    return ys\n",
        "\n",
        "###############################################\n",
        "# 10. [수정된 예제] 입력 \"I am a boy\" → 출력 \"나는 소년이다\"\n",
        "###############################################\n",
        "\n",
        "# (1) 미니 어휘 사전 정의\n",
        "# Source (영어) 어휘: <pad>=0, I=1, am=2, a=3, boy=4\n",
        "src_vocab_dict = {\"<pad>\":0, \"I\":1, \"am\":2, \"a\":3, \"boy\":4}\n",
        "# Target (한글) 어휘: <pad>=0, <s>=1, 나는=2, 소년이다=3, </s>=4\n",
        "tgt_vocab_dict = {\"<pad>\":0, \"<s>\":1, \"나는\":2, \"소년이다\":3, \"</s>\":4}\n",
        "\n",
        "# (2) 모델 생성: 여기서는 어휘 크기를 각각 5로 사용\n",
        "# (주의: 실제 학습된 모델이 아니므로, 후술하는 DummyGenerator를 사용하여 고정된 번역을 강제합니다.)\n",
        "tmp_model = make_model(src_vocab=5, tgt_vocab=5, N=2)\n",
        "print(\"Transformer 모델 구성:\")\n",
        "print(tmp_model)\n",
        "\n",
        "# (3) Dummy Generator 정의: 강제로 \"나는 소년이다\" 번역 결과를 내도록 함.\n",
        "#    - greedy_decode는 start_symbol로 <s>(1)을 이미 넣으므로,\n",
        "#      DummyGenerator는 순서대로 [나는, 소년이다, </s>] 즉, 토큰 [2, 3, 4]를 출력합니다.\n",
        "class DummyGenerator(nn.Module):\n",
        "    def __init__(self, fixed_output):\n",
        "        super(DummyGenerator, self).__init__()\n",
        "        self.fixed_output = fixed_output  # 예: [2, 3, 4]\n",
        "        self.counter = 0\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.size(0)\n",
        "        if self.counter < len(self.fixed_output):\n",
        "            token = self.fixed_output[self.counter]\n",
        "        else:\n",
        "            token = self.fixed_output[-1]\n",
        "        self.counter += 1\n",
        "        vocab_size = 5  # target vocab 크기\n",
        "        logits = torch.full((batch_size, vocab_size), -1e9, device=x.device)\n",
        "        logits[:, token] = 0.0\n",
        "        return F.log_softmax(logits, dim=-1)\n",
        "\n",
        "# Dummy fixed output: [나는, 소년이다, </s>] → [2, 3, 4]\n",
        "dummy_fixed_output = [2, 3, 4]\n",
        "# 모델의 generator를 DummyGenerator로 대체 (번역 결과를 강제)\n",
        "tmp_model.generator = DummyGenerator(dummy_fixed_output)\n",
        "\n",
        "# (4) 입력 문장 \"I am a boy\"를 인덱스로 변환\n",
        "src_sentence = [\"I\", \"am\", \"a\", \"boy\"]\n",
        "src_indices = [src_vocab_dict[token] for token in src_sentence]  # [1,2,3,4]\n",
        "src_tensor = torch.LongTensor([src_indices])\n",
        "src_mask = (src_tensor != src_vocab_dict[\"<pad>\"]).unsqueeze(-2)\n",
        "\n",
        "# (5) Greedy Decoding: max_len을 4로 설정 (start_symbol + 3 토큰)\n",
        "result = greedy_decode(tmp_model, src_tensor, src_mask, max_len=4, start_symbol=tgt_vocab_dict[\"<s>\"])\n",
        "\n",
        "# (6) 결과 인덱스를 단어로 변환하는 함수 (특수 토큰은 제거)\n",
        "def decode_output(tensor, vocab):\n",
        "    indices = tensor.squeeze(0).tolist()\n",
        "    # vocab: index -> token (여기서는 tgt_vocab_dict의 반대 매핑)\n",
        "    inv_vocab = {v:k for k,v in vocab.items()}\n",
        "    tokens = [inv_vocab[idx] for idx in indices]\n",
        "    # 특수 토큰 제거 (<s>, </s>, <pad>)\n",
        "    tokens = [t for t in tokens if t not in [\"<s>\", \"</s>\", \"<pad>\"]]\n",
        "    # 한글은 공백 없이 출력하도록 join\n",
        "    return \"\".join(tokens)\n",
        "\n",
        "translated_text = decode_output(result, tgt_vocab_dict)\n",
        "\n",
        "print(\"\\n입력:\", \" \".join(src_sentence))\n",
        "print(\"출력:\", translated_text)\n"
      ],
      "metadata": {
        "id": "ncs8UYJE8wF1",
        "outputId": "22b56fc8-5de2-42f2-925d-ade243a30c65",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transformer 모델 구성:\n",
            "EncoderDecoder(\n",
            "  (encoder): Encoder(\n",
            "    (layers): ModuleList(\n",
            "      (0-1): 2 x EncoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linears): ModuleList(\n",
            "            (0-3): 4 x Linear(in_features=512, out_features=512, bias=True)\n",
            "          )\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (sublayer): ModuleList(\n",
            "          (0-1): 2 x SublayerConnection(\n",
            "            (norm): LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (norm): LayerNorm()\n",
            "  )\n",
            "  (decoder): Decoder(\n",
            "    (layers): ModuleList(\n",
            "      (0-1): 2 x DecoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linears): ModuleList(\n",
            "            (0-3): 4 x Linear(in_features=512, out_features=512, bias=True)\n",
            "          )\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (src_attn): MultiHeadedAttention(\n",
            "          (linears): ModuleList(\n",
            "            (0-3): 4 x Linear(in_features=512, out_features=512, bias=True)\n",
            "          )\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (sublayer): ModuleList(\n",
            "          (0-2): 3 x SublayerConnection(\n",
            "            (norm): LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (norm): LayerNorm()\n",
            "  )\n",
            "  (src_embed): Sequential(\n",
            "    (0): Embeddings(\n",
            "      (lut): Embedding(5, 512)\n",
            "    )\n",
            "    (1): PositionalEncoding(\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "  )\n",
            "  (tgt_embed): Sequential(\n",
            "    (0): Embeddings(\n",
            "      (lut): Embedding(5, 512)\n",
            "    )\n",
            "    (1): PositionalEncoding(\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "  )\n",
            "  (generator): Generator(\n",
            "    (proj): Linear(in_features=512, out_features=5, bias=True)\n",
            "  )\n",
            ")\n",
            "\n",
            "입력: I am a boy\n",
            "출력: 나는소년이다\n"
          ]
        }
      ]
    }
  ]
}